

# 音视频相关术语


## 1.1 视频编码

视频是连续的图像序列，由连续的帧构成，一帧即为一幅图像。由于人眼的视觉暂留效应，当帧序列以一定的速率播放时，我们看到的就是动作连续的视频。由于连续的帧之间相似性极高，为便于储存传输，我们需要对原始的视频进行编码压缩，以去除空间、时间维度的冗余。

所谓视频编码方式是指通过压缩技术，将原始视频像素数据(RGB、YUV等)转换成另一种视频格式文件的方式。视频压缩技术是计算机处理视频的前提。视频信号数字化后数据带宽很高，通常在20MB/秒以上，因此计算机很难对之进行保存和处理。采用压缩技术通常数据带宽降到1-10MB/秒，这样就可以将视频信号保存在计算机中并作相应的处理。常用的编解码标准有国际电联的`H.26x系列`，运动静止图像专家组的M-JPEG和国际标准化组织运动图像专家组的`MPEG系列`此外在互联网上被广泛应用的还有Real-Networks的`RealVideo`、微软公司的`WMV`、Apple公司的`QuickTime`(Apple)等。

**H.26x系列**

由ITU国际电传视讯联盟主导，侧网络传输，注意该标准只针对视频编码，包括H.261、H.262、H.263、H.263+、H.263++、**H.264**(与MPEG4 AVC的结晶)

**MPEG系列**

MPEG系列由ISO(国际标准化组织)下属的MPEG运动图像专家组开发，视频编码
方面主要是MPEGl(VCD用的就是它)、 MPEG2(DVD使用，DVD音频没有采用MPEG)、 MPEG4(DVDRIP用的都是它的变种，如DivX、XviD等)、 MPEG4 AVC(正热门)。其还有音频编码方面，主要是MPEG Audio Layer 1/2、MPEG Audio Layer 3(大名鼎鼎的MP3)、 MPEG-2 AAC、MPEG-4 AAC等


## 1.2 音频编码

常见的音频编码格式有AAC、MP3、AC3：

**AAC**

一种专为声音数据设计的文件压缩格式，它采用了全新的算法进行编码，在感觉声音质没有明显降低的前提下，可使文件更加小巧。相对于MP3，AAC格式音质更佳、文件更小。但是它属于**有损压缩**格式，与时下流行的APE、FLAC等无损压缩格式相比音质存在“本质上”的差距，加之传输速度更快的USB3.0和16GB以上大容量MP3加速普及，这也使得AAC头上“小巧”的光环逐渐暗淡。

**MP3**

MP3(Moving Picture Experts Group Audio Layer III-动态影像专家压缩标准音频层面3)是一种音频压缩技术，以1：10甚至1：12的压缩率大幅度压缩成较小的文件。其利用人耳对高颇声音信号不敏感的特性，将时域波形信号转换成频域信号，井划分成多个频段，对不同的频段使用不同的压缩率，对高频信号使
用大压缩率（甚至忽略信号），对低频信号使用小压缩率，保证信号不失真。这样一来就相当于抛弃人耳基本听不到的高频声音，只保留能昕到的低频部分。

**AC3**

AC3(Audio Coding Version 3)是Dolby实验室发展的**有损音频编码**格式。被广泛应用于5.1声道，是Dolby Pro Logic的继承者，不同的地方在于 AC3提供了6个独立声道而Pro Logic混合其环绕声道。AC3普及程度很高，以 384~448kb/s的码率应用于激光唱片和DVD，也经常以640kb/s的码率广泛应用于电影院。Dolby AC3提供的环绕声系统由5个全频域声道和1个超低音声道组成，被称为5.1声道。
5个全频域声道包括左前、中央、右前、左后、右后，超低音声道主要提供一些额外的低音信息，使一些场景(爆炸、撞击等)的声音效果更好。


## 1.3 多媒体播放组件

Android提供的多媒体组件包含MediaPlayer、MediaCodec、OMX、StageFright、AudioTrack等：

- MediaPlayer：播放控制
- MediaCodec：音视频硬编解码
- OMX：多媒体部分采用的编解码标准
- StageFright：它是一个框架，替代之前的OpenCore，主要做了一个OMX层，仅仅对Open Core的omx-component部分做了引用。StageFright是在MediaPlayerService层加入的，和OpenCore是并列的。StageFright在Android中是以共享库的形式存在的(libstagefright.so)，其中的NuPlayer/AwesomePlayer模块可用来播放音视频。NuPlayer/AwesomePlayer 提供了许多API供上层应用程序(Java/JNI)调用
- AudiTrack：音频播放

## 1.4 常见的多媒体框架及解决方案

常见的多媒体框架及解决方案有VLC、FFmpeg、GStreamer等：

- VLC：Video LAN Client是一款自由、开源的跨平台多媒体播放器及框架
- FFmpeg：多媒体解决方案，不是多媒体框架，广泛用于音视频开发中
- GStreamer：一套构建流媒体应用的开源多媒体框架


## 1.5 音视频相关名词、术语和概念

**帧率**

帧率(Frame Rate)是用于测量显示帧数的量度。所谓的测量单位为**每秒显示帧数**(fps-Frames per second)或“赫兹”(Hz)。每秒显示帧数fps或者帧率表示图形处理器处理时每秒能够更新的次数。高帧率可以得到更流畅、更逼真的动画。一般来说，30fps就是可以接受的，60fps可以明显提升交互感和逼真感，超过75fps就不容易察觉明显的流畅度提升了。如果帧率超过屏幕刷新率，只会浪费图像处理能力，因为监视器不能以这么快的速度更新，这样超过刷新率的帧率就液费掉了。

**分辨率**

视频分辨率是指视频成像产品所形成的图像大小或尺寸

**刷新率**

刷新率是指屏幕每秒被刷新的次数，刷新率分为垂直刷新率和水平刷新率，一般提到的刷新率通常指垂直刷新率。垂直刷新率表示屏幕上图像每秒重绘多少次，也就是每秒屏幕刷新的次数，以Hz(赫兹)为单位。刷新率越高，图像就越稳定，图像显示就越自然清晰，到眼睛的影响也越小。刷新率越低，图像闪烁和抖动得就越厉害，眼睛疲劳得就越快。一般来说，如能达到80Hz以上的刷新率，就可以完全消除图像闪烁和抖动感，眼睛也不太容易疲劳。

**编码格式**

编码的目的是压缩数据量，采用编码算法压缩冗余数据。常用的编码格式有这两种MPEG(MPEG-2、MPEG-4)和H.26X(H.263、H.264/AVC、H.265/HEVC)

**封装格式**

将已经编码压缩好的视频轨和音频轨按照一定的格式放到一个文件中，也就是说仅仅是一个外壳，或者大家把它当成一个放视频轨和音频轨的文件夹也可以。说得通俗点，视频轨相当于饭，而音频轨相当于菜，封装格式就是一个碗，或者一个锅，用来盛放饭菜的容器。封装格式有MKV、AVI、MP4、WMV等

**码率**

码率（比特率）是单位时间播放连续的媒体（如压缩后的音频或视频）的比特
量。 比特率越高，带宽消耗得越多。`文件大小(b)=码率(b/s)x时长(s)`。

码率越大画质越好，视频越流畅这种说法是错误的，视频质量和码率、编码算法都有关系。

**DTS & PTS**

- DTS(Decode Time Stamp)用于标示读入内存中的比特流在什么时候开始送入解码器中进行解码
- PTS(Presentation Time Stamp)用于度量解码后的视频帧什么时候被显示出
来。

**YUV & RGB**
 
YUV和RGB是指颜色空间模型
- YUV：也被称作YCrCb，是被欧洲电视系统所采用的一种颜色编码方法。其中Y代表亮度，UV代表色差，U和V是构成颜色的两个分量。
- RGB：一种颜色空间模型，通过对红R、绿G、蓝B 3个颜色通道的变化以及它们相互之间的叠加来得到各式各样的颜色，RGB代表红绿蓝3个通道的颜色

**视频帧及音频帧**

常见的视频帧有I、P、B帧，I帧表示关键帧，是画面完整保留的帧。P帧(差别帧)表示这一帧和之前一个关键帧的差别，解码时需要用之前缓存的画面叠加本帧定义的差别生成最终画面。B帧是双向差别帧，记录本帧与前后帧的差别。B帧压缩率高，但是解码时CPU比较吃力。

与I帧相似程度极高达到95%以上编码成B帧，70%相似度编码为P帧，I帧和P帧之间有B帧做过度，通常I帧和P帧之间有多个B帧，两个I帧之间有多个B和P帧。














